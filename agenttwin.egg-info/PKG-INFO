Metadata-Version: 2.4
Name: agenttwin
Version: 1.0.0
Summary: Multi-Agent Reinforcement Learning for Tennessee Eastman Process Control
Home-page: https://github.com/agenttwin/multi-agent-digital-twin
Author: Multi-Agent Digital Twin Research Team
Author-email: research@agenttwin.ai
Project-URL: Bug Reports, https://github.com/agenttwin/multi-agent-digital-twin/issues
Project-URL: Source, https://github.com/agenttwin/multi-agent-digital-twin
Project-URL: Documentation, https://agenttwin.readthedocs.io/
Project-URL: Paper, https://arxiv.org/abs/2024.xxxxx
Keywords: reinforcement learning,multi-agent systems,digital twin,process control,safety shields,tennessee eastman,industrial ai
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Chemistry
Classifier: Topic :: System :: Distributed Computing
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: numpy>=1.24.0
Requires-Dist: scipy>=1.10.0
Requires-Dist: pandas>=2.0.0
Requires-Dist: matplotlib>=3.7.0
Requires-Dist: seaborn>=0.12.0
Requires-Dist: torch>=2.0.0
Requires-Dist: torchvision>=0.15.0
Requires-Dist: torchaudio>=2.0.0
Requires-Dist: scikit-learn>=1.3.0
Requires-Dist: stable-baselines3[extra]>=2.0.0
Requires-Dist: gymnasium>=0.29.0
Requires-Dist: tensorboard>=2.13.0
Requires-Dist: cvxpy>=1.3.0
Requires-Dist: osqp>=0.6.0
Requires-Dist: qpsolvers[open]>=3.0.0
Requires-Dist: control>=0.9.0
Requires-Dist: slycot>=0.5.0
Requires-Dist: do-mpc>=4.5.0
Requires-Dist: casadi>=3.6.0
Requires-Dist: jupyter>=1.0.0
Requires-Dist: ipython>=8.0.0
Requires-Dist: ipykernel>=6.0.0
Requires-Dist: plotly>=5.15.0
Requires-Dist: kaleido>=0.2.1
Requires-Dist: pytest>=7.0.0
Requires-Dist: black>=23.0.0
Requires-Dist: flake8>=6.0.0
Requires-Dist: PyYAML>=6.0.0
Requires-Dist: tqdm>=4.65.0
Requires-Dist: wandb>=0.15.0
Requires-Dist: openpyxl>=3.1.0
Requires-Dist: jsonschema>=4.17.0
Requires-Dist: accelerate>=0.20.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: flake8>=6.0.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Requires-Dist: pre-commit>=3.0.0; extra == "dev"
Provides-Extra: docs
Requires-Dist: sphinx>=5.0.0; extra == "docs"
Requires-Dist: sphinx-rtd-theme>=1.2.0; extra == "docs"
Requires-Dist: myst-parser>=1.0.0; extra == "docs"
Provides-Extra: apple
Requires-Dist: accelerate>=0.20.0; extra == "apple"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: project-url
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

 # Multi-Agent Digital Twin for Joint Scheduling and Control on the Tennessee Eastman Process

This repository contains the complete implementation and paper for "Multi-Agent Digital Twin for Joint Scheduling and Control on the Tennessee Eastman Process" submitted to a Q1 journal.

## Overview

This work presents a two-time-scale multi-agent reinforcement learning approach for integrated scheduling and control on the Tennessee Eastman Process (TEP). The system combines:

- A scheduler agent operating on slow (minutes) timescales for production planning
- Multiple controller agents operating on fast (seconds) timescales for regulatory control  
- A safety shield using quadratic programming with PID fallback
- Coordination through intent vectors and readiness signals

## Repository Structure

```
agenttwin_paper/
├── envs/           # Tennessee Eastman Process environment
├── control/        # Baseline controllers (PID, NMPC)
├── shield/         # Safety shield implementation
├── agents/         # Multi-agent RL implementations
├── train/          # Training scripts and procedures
├── eval/           # Evaluation and plotting utilities
├── configs/        # Configuration files
├── results/        # Experimental results
├── figs/           # Generated figures
├── paper/          # LaTeX paper source
├── data/           # Datasets and scenarios
├── models/         # Trained model weights
└── scripts/        # Utility scripts
```

## Quick Start

### Requirements

- Python 3.8+
- PyTorch (with MPS support for Apple Silicon)
- Stable-Baselines3
- OSQP/QPSOLVERS
- DO-MPC/CasADi
- Standard scientific Python stack

### Installation

```bash
# Create conda environment
conda env create -f environment.yml
conda activate agenttwin

# Or install with pip
pip install -r requirements.txt
```

### Reproduction

To reproduce all results from the paper:

```bash
make reproduce
```

This will:
1. Run all baseline experiments (PID, NMPC, schedule-then-control)
2. Train the multi-agent system
3. Generate all figures and tables
4. Compile the paper PDF

## Experimental Scenarios

The evaluation covers five scenarios (S1-S5) with varying complexity:

- **S1**: Basic grade changes without disturbances
- **S2**: Grade changes with feed composition drift
- **S3**: Grade changes with reactor cooling disturbances
- **S4**: Grade changes with sensor bias
- **S5**: Grade changes with randomized fault injection

## Key Results

The multi-agent approach demonstrates:
- Reduced off-spec time compared to sequential scheduling
- Lower economic cost than PID cascades
- Improved constraint satisfaction through safety shielding
- Faster recovery from disturbances

## Citation

```bibtex
@article{alqithami2025agenttwin,
  title={Multi-Agent Digital Twin for Joint Scheduling and Control on the Tennessee Eastman Process},
  author={Alqithami, Saad},
  journal={Processes},
  year={2025}
}
```

## License

MIT License - see LICENSE file for details.

## Contact

For questions about this work, please contact: [contact information]

