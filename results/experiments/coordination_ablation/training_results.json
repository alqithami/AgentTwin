{
  "behavior_cloning": {},
  "individual_training": {
    "duration": 824.8511071205139,
    "evaluation_results": {
      "episode_rewards_mean": -1123323.1645294018,
      "episode_rewards_std": 2074.337181720091,
      "episode_rewards_min": -1126586.8047558235,
      "episode_rewards_max": -1118351.1491278112,
      "episode_lengths_mean": 1000.0,
      "episode_lengths_std": 0.0,
      "episode_lengths_min": "1000",
      "episode_lengths_max": "1000",
      "economic_costs_mean": -409092.42172483506,
      "economic_costs_std": 32253.395029763113,
      "economic_costs_min": -459511.77790590754,
      "economic_costs_max": -358303.2476021708,
      "constraint_violations_mean": 32075.2,
      "constraint_violations_std": 1966.3119182876353,
      "constraint_violations_min": "28994",
      "constraint_violations_max": "35156",
      "off_spec_times_mean": 1.6666666666666916,
      "off_spec_times_std": 0.0,
      "off_spec_times_min": 1.6666666666666916,
      "off_spec_times_max": 1.6666666666666916,
      "safety_interventions_mean": 0.0,
      "safety_interventions_std": 0.0,
      "safety_interventions_min": "0",
      "safety_interventions_max": "0"
    },
    "timestamp": "2025-08-16T02:33:33.909700"
  },
  "joint_training": {},
  "evaluation": {
    "scenario_results": {
      "S1": {
        "episode_rewards_mean": -1122334.6903840248,
        "episode_rewards_std": 1475.262175485142,
        "episode_rewards_min": -1123975.7793244673,
        "episode_rewards_max": -1119651.7927868452,
        "episode_lengths_mean": 1000.0,
        "episode_lengths_std": 0.0,
        "episode_lengths_min": "1000",
        "episode_lengths_max": "1000",
        "economic_costs_mean": -62180.92080263852,
        "economic_costs_std": 32338.525122581625,
        "economic_costs_min": -112950.2764960257,
        "economic_costs_max": -11172.942227063359,
        "constraint_violations_mean": 3762.3,
        "constraint_violations_std": 1963.683174547259,
        "constraint_violations_min": "685",
        "constraint_violations_max": "6839",
        "off_spec_times_mean": 1.6666666666666916,
        "off_spec_times_std": 0.0,
        "off_spec_times_min": 1.6666666666666916,
        "off_spec_times_max": 1.6666666666666916,
        "safety_interventions_mean": 0.0,
        "safety_interventions_std": 0.0,
        "safety_interventions_min": "0",
        "safety_interventions_max": "0"
      },
      "S2": {
        "episode_rewards_mean": -1123446.4624107908,
        "episode_rewards_std": 1527.5424636622338,
        "episode_rewards_min": -1126618.165851187,
        "episode_rewards_max": -1121060.766140129,
        "episode_lengths_mean": 1000.0,
        "episode_lengths_std": 0.0,
        "episode_lengths_min": "1000",
        "episode_lengths_max": "1000",
        "economic_costs_mean": -62584.84977514893,
        "economic_costs_std": 32619.478009332575,
        "economic_costs_min": -113538.06247338976,
        "economic_costs_max": -10891.029203769831,
        "constraint_violations_mean": 3767.0,
        "constraint_violations_std": 1966.2769896431175,
        "constraint_violations_min": "685",
        "constraint_violations_max": "6847",
        "off_spec_times_mean": 1.6666666666666916,
        "off_spec_times_std": 0.0,
        "off_spec_times_min": 1.6666666666666916,
        "off_spec_times_max": 1.6666666666666916,
        "safety_interventions_mean": 0.0,
        "safety_interventions_std": 0.0,
        "safety_interventions_min": "0",
        "safety_interventions_max": "0"
      },
      "baselines": {
        "pid_cascade": {
          "episode_rewards_mean": -4884761.649203313,
          "episode_rewards_std": 5098.250978821332,
          "episode_lengths_mean": 1000.0,
          "episode_lengths_std": 0.0
        },
        "nmpc": {
          "episode_rewards_mean": -4886195.624802538,
          "episode_rewards_std": 40835.67892968296,
          "episode_lengths_mean": 1000.0,
          "episode_lengths_std": 0.0
        },
        "schedule_then_control": {
          "episode_rewards_mean": -4903609.037849082,
          "episode_rewards_std": 38360.620914258114,
          "episode_lengths_mean": 1000.0,
          "episode_lengths_std": 0.0
        }
      }
    },
    "timestamp": "2025-08-16T02:33:40.513915"
  }
}