# Multi-Agent Digital Twin for Apple M4 Max

This guide provides specific instructions for setting up and running the Multi-Agent Digital Twin on Apple M4 Max systems.

## üçé Apple M4 Max Optimizations

This implementation is specifically optimized for Apple M4 Max with the following enhancements:

### Performance Optimizations
- **Metal Performance Shaders (MPS)**: PyTorch with native Apple Silicon GPU acceleration
- **Accelerate Framework**: NumPy and SciPy with Apple's optimized BLAS/LAPACK
- **Native ARM64**: All packages compiled for Apple Silicon architecture
- **Optimized Threading**: Thread counts tuned for M4 Max performance cores

### Key Benefits
- **3-5x faster training** compared to CPU-only implementations
- **Native Apple Silicon support** for all dependencies
- **Optimized memory usage** for M4 Max unified memory architecture
- **Real-time performance** for safety shield QP optimization

## üöÄ Quick Start

### One-Command Setup
```bash
# Clone the repository
git clone https://github.com/agenttwin/multi-agent-digital-twin.git
cd multi-agent-digital-twin

# Run Apple M4 Max optimized setup
make apple-setup
```

### Manual Setup
If you prefer manual setup:

```bash
# 1. Install Xcode Command Line Tools (if not already installed)
xcode-select --install

# 2. Install Homebrew (if not already installed)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# 3. Install system dependencies
brew install python@3.11 cmake pkg-config openblas lapack gfortran

# 4. Create conda environment
conda env create -f environment.yml
conda activate agenttwin

# 5. Install the package
pip install -e .
```

## üß™ Verification

Test your installation:

```bash
# Activate environment
conda activate agenttwin

# Run verification
make verify

# Run performance benchmark
make benchmark

# Run quick functionality test
make test
```

Expected output for successful setup:
```
‚úÖ NumPy 1.24.3
‚úÖ PyTorch 2.0.1
‚úÖ MPS (Metal Performance Shaders) available
‚úÖ Stable-Baselines3 2.0.0
‚úÖ Gymnasium 0.29.1
‚úÖ CVXPY 1.3.2
‚úÖ TEP Environment module
‚úÖ Multi-Agent RL System module
```

## üèÉ‚Äç‚ôÇÔ∏è Running Experiments

### Quick Test (5 minutes)
```bash
make reproduce-quick
```

### Full Reproduction (30-60 minutes)
```bash
make reproduce
```

### Individual Components
```bash
# Training only
make train

# Evaluation only
make eval

# Results generation only
make results
```

## üìä Expected Performance

On Apple M4 Max, you should expect:

| Component | Performance | Time |
|-----------|-------------|------|
| Environment Setup | Native ARM64 | < 1 minute |
| Quick Test | MPS Accelerated | 2-3 minutes |
| Individual Training | MPS + Optimized | 10-15 minutes |
| Joint Training | MPS + Coordination | 15-20 minutes |
| Full Evaluation | Parallel Processing | 20-30 minutes |
| Results Generation | Native Plotting | 5-10 minutes |

## üîß Apple M4 Max Specific Settings

The setup automatically configures:

```bash
# Environment variables for optimal performance
export PYTORCH_ENABLE_MPS_FALLBACK=1
export OMP_NUM_THREADS=8  # Optimized for M4 Max performance cores
export MKL_NUM_THREADS=8
export VECLIB_MAXIMUM_THREADS=8
export NUMEXPR_NUM_THREADS=8
export CVXPY_DEFAULT_SOLVER=OSQP
export MPLBACKEND=MacOSX
```

## üêõ Troubleshooting

### Common Issues

#### MPS Not Available
```bash
# Check MPS availability
python -c "import torch; print(f'MPS available: {torch.backends.mps.is_available()}')"

# If False, reinstall PyTorch
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

#### CVXPY Solver Issues
```bash
# Install additional solvers
pip install cvxopt scs ecos
```

#### Memory Issues
```bash
# Reduce batch size in training config
# Edit agents/multi_agent_system.py
# Change batch_size from 256 to 128
```

#### Conda Environment Issues
```bash
# Remove and recreate environment
conda env remove -n agenttwin
conda env create -f environment.yml
```

### Performance Issues

If performance is slower than expected:

1. **Check MPS Usage**:
   ```bash
   # Monitor GPU usage
   sudo powermetrics --samplers gpu_power -n 1 -i 1000
   ```

2. **Verify Thread Settings**:
   ```bash
   python -c "import torch; print(f'Threads: {torch.get_num_threads()}')"
   ```

3. **Check Memory Pressure**:
   ```bash
   # Monitor memory usage
   memory_pressure
   ```

## üìà Performance Benchmarks

Typical performance on Apple M4 Max:

```
Performance Benchmark
====================
NumPy matrix multiplication (1000x1000): 0.045s
PyTorch CPU matrix multiplication (1000x1000): 0.052s
PyTorch MPS matrix multiplication (1000x1000): 0.012s
MPS speedup: 4.33x
```

## üîÑ Updates and Maintenance

Keep your environment updated:

```bash
# Update conda packages
conda update --all

# Update pip packages
pip install --upgrade -r requirements.txt

# Update the project
git pull origin main
pip install -e .
```

## üìû Support

For Apple M4 Max specific issues:

1. Check the [troubleshooting section](#troubleshooting) above
2. Verify your system meets the requirements
3. Run `make info` to get system information
4. Open an issue with the output of `make verify`

## üéØ Next Steps

After successful setup:

1. **Run the quick test**: `make test`
2. **Generate results**: `make reproduce-quick`
3. **Explore the code**: Start with `envs/tep_env.py`
4. **Modify experiments**: Edit `train/training_pipeline.py`
5. **Create custom plots**: Modify `eval/generate_results.py`

## üìö Additional Resources

- [Apple Silicon ML Guide](https://developer.apple.com/metal/pytorch/)
- [PyTorch MPS Documentation](https://pytorch.org/docs/stable/notes/mps.html)
- [Conda Apple Silicon Guide](https://conda-forge.org/docs/user/tipsandtricks.html#using-multiple-channels)

---

**Happy experimenting on your Apple M4 Max! üöÄ**

